{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 22:01:31.253016: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-04 22:01:31.298390: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "from tslearn.shapelets import ShapeletModel, grabocka_params_to_shapelet_size_dict\n",
    "from tslearn.shapelets import ShapeletModel, grabocka_params_to_shapelet_size_dict\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Specify dataset path to where you downloaded https://www.eurocrops.tum.de/downloads.html\n",
    "dataset_dir = \"/home/fin_eckhoff/Projects/TimeSeries/TimeSeries\"\n",
    "\n",
    "# Get all paths\n",
    "train_h5_dir  = os.path.join(dataset_dir, 'm1615987/HDF5s/train/')\n",
    "train_csv_dir = os.path.join(dataset_dir, 'm1615987/csv_labels/train/')\n",
    "test_h5_dir   = os.path.join(dataset_dir, 'm1615987/HDF5s/test/')\n",
    "test_csv_dir  = os.path.join(dataset_dir, 'm1615987/csv_labels/test/')\n",
    "\n",
    "# check they all exist\n",
    "print(os.path.exists(test_csv_dir))\n",
    "print(os.path.exists(test_h5_dir))\n",
    "print(os.path.exists(train_csv_dir))\n",
    "print(os.path.exists(train_h5_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/AT112', '/AT122', '/AT123', '/AT124', '/AT125', '/AT127', '/AT130', '/AT223']\n"
     ]
    }
   ],
   "source": [
    "selected_file = os.path.join(train_h5_dir, 'AT_T33UWP_train.h5')\n",
    "\n",
    "# load the .h5 file using pandas.\n",
    "hdf = pd.HDFStore(selected_file, mode='r') \n",
    "\n",
    "# list all the keys, which are regions, in the country-region?\n",
    "print(hdf.keys())\n",
    "\n",
    "# extract a subset - the first region from the list\n",
    "df_data1 = hdf.get(hdf.keys()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_file = h5py.File(selected_file, 'r')\n",
    "regions =  list(h5_file.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fin_eckhoff/Projects/TimeSeries/TimeSeries/m1615987/csv_labels/train/demo_eurocrops_AT112.csv\n",
      "Exists: True\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = os.path.join(train_csv_dir, 'demo_eurocrops_' + regions[0] + '.csv')\n",
    "print(csv_file_path)\n",
    "print(\"Exists:\", os.path.exists(csv_file_path))\n",
    "\n",
    "df_labels = pd.read_csv(csv_file_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_labels[[\"crpgrpn\"]].to_numpy()\n",
    "encoder = OneHotEncoder()\n",
    "one_hot_encoded_labels = encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "recno = df_labels[\"crpgrpn\"].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_leguminous_plants</th>\n",
       "      <th>x0_fruit_of_temperate_climate_zones</th>\n",
       "      <th>x0_other_cereals_for_the_production_of_grain</th>\n",
       "      <th>x0_pasture_meadow</th>\n",
       "      <th>x0_nuts</th>\n",
       "      <th>x0_summer_common_wheat_and_spelt</th>\n",
       "      <th>x0_winter_common_wheat_and_spelt</th>\n",
       "      <th>x0_fresh_vegetables_melons_and_strawberries</th>\n",
       "      <th>x0_other_plants_harvested_green</th>\n",
       "      <th>x0_aromatic_plants_medicinal_and_culinary_plants</th>\n",
       "      <th>...</th>\n",
       "      <th>x0_sunflower_and_yellow_bloomer</th>\n",
       "      <th>x0_potatoes</th>\n",
       "      <th>x0_vineyards</th>\n",
       "      <th>x0_not_known</th>\n",
       "      <th>x0_winter_barley</th>\n",
       "      <th>x0_winter_durum_wheat</th>\n",
       "      <th>x0_winter_rape</th>\n",
       "      <th>x0_winter_rye</th>\n",
       "      <th>x0_winter_triticale</th>\n",
       "      <th>x0_sugar_beet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6259</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6260</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6261</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6262</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6263</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6264 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x0_leguminous_plants  x0_fruit_of_temperate_climate_zones  \\\n",
       "0                        1                                    0   \n",
       "1                        1                                    0   \n",
       "2                        1                                    0   \n",
       "3                        1                                    0   \n",
       "4                        1                                    0   \n",
       "...                    ...                                  ...   \n",
       "6259                     0                                    0   \n",
       "6260                     0                                    0   \n",
       "6261                     0                                    0   \n",
       "6262                     0                                    0   \n",
       "6263                     0                                    1   \n",
       "\n",
       "      x0_other_cereals_for_the_production_of_grain  x0_pasture_meadow  \\\n",
       "0                                                0                  0   \n",
       "1                                                0                  0   \n",
       "2                                                0                  0   \n",
       "3                                                0                  0   \n",
       "4                                                0                  0   \n",
       "...                                            ...                ...   \n",
       "6259                                             0                  0   \n",
       "6260                                             0                  0   \n",
       "6261                                             0                  0   \n",
       "6262                                             0                  0   \n",
       "6263                                             0                  0   \n",
       "\n",
       "      x0_nuts  x0_summer_common_wheat_and_spelt  \\\n",
       "0           0                                 0   \n",
       "1           0                                 0   \n",
       "2           0                                 0   \n",
       "3           0                                 0   \n",
       "4           0                                 0   \n",
       "...       ...                               ...   \n",
       "6259        0                                 0   \n",
       "6260        0                                 0   \n",
       "6261        0                                 0   \n",
       "6262        0                                 0   \n",
       "6263        0                                 0   \n",
       "\n",
       "      x0_winter_common_wheat_and_spelt  \\\n",
       "0                                    0   \n",
       "1                                    0   \n",
       "2                                    0   \n",
       "3                                    0   \n",
       "4                                    0   \n",
       "...                                ...   \n",
       "6259                                 0   \n",
       "6260                                 0   \n",
       "6261                                 0   \n",
       "6262                                 0   \n",
       "6263                                 0   \n",
       "\n",
       "      x0_fresh_vegetables_melons_and_strawberries  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "...                                           ...   \n",
       "6259                                            0   \n",
       "6260                                            0   \n",
       "6261                                            0   \n",
       "6262                                            0   \n",
       "6263                                            0   \n",
       "\n",
       "      x0_other_plants_harvested_green  \\\n",
       "0                                   0   \n",
       "1                                   0   \n",
       "2                                   0   \n",
       "3                                   0   \n",
       "4                                   0   \n",
       "...                               ...   \n",
       "6259                                0   \n",
       "6260                                0   \n",
       "6261                                0   \n",
       "6262                                0   \n",
       "6263                                0   \n",
       "\n",
       "      x0_aromatic_plants_medicinal_and_culinary_plants  ...  \\\n",
       "0                                                    0  ...   \n",
       "1                                                    0  ...   \n",
       "2                                                    0  ...   \n",
       "3                                                    0  ...   \n",
       "4                                                    0  ...   \n",
       "...                                                ...  ...   \n",
       "6259                                                 0  ...   \n",
       "6260                                                 0  ...   \n",
       "6261                                                 0  ...   \n",
       "6262                                                 0  ...   \n",
       "6263                                                 0  ...   \n",
       "\n",
       "      x0_sunflower_and_yellow_bloomer  x0_potatoes  x0_vineyards  \\\n",
       "0                                   0            0             0   \n",
       "1                                   0            0             0   \n",
       "2                                   0            0             0   \n",
       "3                                   0            0             0   \n",
       "4                                   0            0             0   \n",
       "...                               ...          ...           ...   \n",
       "6259                                0            0             0   \n",
       "6260                                0            0             0   \n",
       "6261                                0            0             0   \n",
       "6262                                0            0             0   \n",
       "6263                                0            0             0   \n",
       "\n",
       "      x0_not_known  x0_winter_barley  x0_winter_durum_wheat  x0_winter_rape  \\\n",
       "0                0                 0                      0               0   \n",
       "1                0                 0                      0               0   \n",
       "2                0                 0                      0               0   \n",
       "3                0                 0                      0               0   \n",
       "4                0                 0                      0               0   \n",
       "...            ...               ...                    ...             ...   \n",
       "6259             0                 0                      0               0   \n",
       "6260             0                 0                      0               0   \n",
       "6261             0                 0                      0               0   \n",
       "6262             0                 0                      0               0   \n",
       "6263             0                 0                      0               0   \n",
       "\n",
       "      x0_winter_rye  x0_winter_triticale  x0_sugar_beet  \n",
       "0                 0                    0              0  \n",
       "1                 0                    0              0  \n",
       "2                 0                    0              0  \n",
       "3                 0                    0              0  \n",
       "4                 0                    0              0  \n",
       "...             ...                  ...            ...  \n",
       "6259              0                    0              1  \n",
       "6260              0                    0              1  \n",
       "6261              0                    0              1  \n",
       "6262              0                    0              1  \n",
       "6263              0                    0              0  \n",
       "\n",
       "[6264 rows x 31 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crpgrpn\n",
       "winter_common_wheat_and_spelt                     1381\n",
       "pasture_meadow                                     985\n",
       "grain_maize                                        766\n",
       "soya                                               600\n",
       "other_plants_harvested_green                       395\n",
       "vineyards                                          366\n",
       "winter_barley                                      244\n",
       "sunflower_and_yellow_bloomer                       244\n",
       "others                                             215\n",
       "leguminous_plants                                  156\n",
       "sugar_beet                                         151\n",
       "winter_triticale                                   113\n",
       "fresh_vegetables_melons_and_strawberries           102\n",
       "winter_rye                                          74\n",
       "winter_rape                                         67\n",
       "millet                                              66\n",
       "winter_durum_wheat                                  65\n",
       "summer_durum_wheat                                  64\n",
       "summer_barley                                       47\n",
       "other_cereals_for_the_production_of_grain           46\n",
       "fruit_of_temperate_climate_zones                    34\n",
       "cucurbits                                           21\n",
       "potatoes                                            19\n",
       "summer_common_wheat_and_spelt                       17\n",
       "not_known                                            8\n",
       "other_industrial_crops_not_mentioned_elsewhere       6\n",
       "aromatic_plants_medicinal_and_culinary_plants        5\n",
       "nuts                                                 3\n",
       "summer_oats                                          2\n",
       "other_oil_seed_crops                                 1\n",
       "arable_land_seed_and_seedlings                       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels[\"crpgrpn\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EurocropDataset(Dataset):\n",
    "    \n",
    "  \n",
    "    \n",
    "    def __init__(self, time_series_data, labels, mean = None, std = None):\n",
    "        self.time_series_data = time_series_data\n",
    "        self.labels = labels\n",
    "        \n",
    "        self.min = torch.tensor(self.time_series_data.min()[0])\n",
    "        self.max = torch.tensor(self.time_series_data.max()[0])\n",
    "        \n",
    "        print(self.min, self.max)\n",
    "        #self.data = 2 * (self.time_series_data - self.min) / (self.max - self.min) - 1\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.time_series_data)\n",
    "    def __getitem__(self, idx):\n",
    "        series = self.time_series_data.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        series_tensor = torch.tensor(series, dtype=torch.float32)\n",
    "        series_tensor = 2 * (series_tensor - self.min) / (self.max - self.min) - 1\n",
    "        label_tensor = torch.tensor(label, dtype=torch.float32 )\n",
    "        return series_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699120/1879154529.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  self.min = torch.tensor(self.time_series_data.min()[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1757, 1286,  820,  615,  618,  583,  595,  545,  288,   15,  444,  360,\n",
      "         580]) tensor([ 7456,  7986,  7603,  8994,  9521,  9752,  9961,  9872,  6116,   262,\n",
      "         8295,  6585, 10354])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699120/1879154529.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  self.max = torch.tensor(self.time_series_data.max()[0])\n"
     ]
    }
   ],
   "source": [
    "ds = EurocropDataset(df_data1, one_hot_encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699120/1879154529.py:21: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  series_tensor = torch.tensor(series, dtype=torch.float32)\n",
      "/tmp/ipykernel_1699120/1879154529.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_tensor = torch.tensor(label, dtype=torch.float32 )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 13])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(ds))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Input, Bidirectional, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "from keras import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    recurrent_input = Input(shape=(80,13),name=\"TIMESERIES_INPUT\")\n",
    "    print(recurrent_input.shape)\n",
    "    \n",
    "    rec_layer_one = Bidirectional(LSTM(128, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01),return_sequences=True),name =\"BIDIRECTIONAL_LAYER_1\")(recurrent_input)\n",
    "    rec_layer_one = Dropout(0.1,name =\"DROPOUT_LAYER_1\")(rec_layer_one)\n",
    "    print(rec_layer_one.shape)\n",
    "    \n",
    "    rec_layer_two = Bidirectional(LSTM(64, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01)),name =\"BIDIRECTIONAL_LAYER_2\")(rec_layer_one)\n",
    "    rec_layer_two = Dropout(0.1,name =\"DROPOUT_LAYER_2\")(rec_layer_two)\n",
    "    \n",
    "    print(rec_layer_two.shape)\n",
    "    \n",
    "    \n",
    "    output = Dense(31,activation='softmax',name=\"OUTPUT_LAYER\")(rec_layer_two)\n",
    "    print(output.shape)\n",
    "    model = Model(inputs=[recurrent_input],outputs=[output])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 22:01:41.191228: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-04 22:01:41.191466: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-04 22:01:41.192779: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-04 22:01:41.192988: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-04 22:01:41.193150: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-04 22:01:41.193304: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-04 22:01:41.373982: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-04 22:01:41.374219: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-04 22:01:41.374392: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-04 22:01:41.374548: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 80, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L355\n",
      "2024-07-04 22:01:41.374701: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-04 22:01:41.374858: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-04 22:01:41.409144: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 80, 256)\n",
      "(None, 128)\n",
      "(None, 31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L344-L355\n",
      "2024-07-04 22:01:41.409407: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-04 22:01:41.409602: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-04 22:01:41.409765: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-04 22:01:41.409947: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-04 22:01:41.410095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:0b:00.0, compute capability: 7.0\n",
      "2024-07-04 22:01:41.410510: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-04 22:01:41.410668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 31134 MB memory:  -> device: 1, name: Tesla V100-PCIE-32GB, pci bus id: 0000:13:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "rnn_model = generate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_data1, one_hot_encoded_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='best_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699120/1879154529.py:21: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  series_tensor = torch.tensor(series, dtype=torch.float32)\n",
      "/tmp/ipykernel_1699120/1879154529.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_tensor = torch.tensor(label, dtype=torch.float32 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 22:01:46.819877: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - accuracy: 0.0449 - f1_m: 0.0000e+00 - loss: 9.2507 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fin_eckhoff/miniforge-pypy3/envs/ML/lib/python3.12/site-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_accuracy available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - accuracy: 0.0920 - f1_m: 0.0000e+00 - loss: 6.1601 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.1519 - f1_m: 0.0000e+00 - loss: 4.0348 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2227 - f1_m: 0.0000e+00 - loss: 2.6379 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 5/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2166 - f1_m: 0.0000e+00 - loss: 1.7305 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 6/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2197 - f1_m: 0.0000e+00 - loss: 1.1454 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 7/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2254 - f1_m: 0.0000e+00 - loss: 0.7716 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 8/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2099 - f1_m: 0.0000e+00 - loss: 0.5336 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 9/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2198 - f1_m: 0.0000e+00 - loss: 0.3841 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 10/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2110 - f1_m: 0.0000e+00 - loss: 0.2905 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 11/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2069 - f1_m: 0.0000e+00 - loss: 0.2319 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 12/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2182 - f1_m: 0.0000e+00 - loss: 0.1945 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 13/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2207 - f1_m: 0.0000e+00 - loss: 0.1713 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 14/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2173 - f1_m: 0.0000e+00 - loss: 0.1564 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 15/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2254 - f1_m: 0.0000e+00 - loss: 0.1457 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 16/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2185 - f1_m: 0.0000e+00 - loss: 0.1394 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 17/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - accuracy: 0.2145 - f1_m: 0.0000e+00 - loss: 0.1345 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 18/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2194 - f1_m: 0.0000e+00 - loss: 0.1309 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 19/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2151 - f1_m: 0.0000e+00 - loss: 0.1284 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 20/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2200 - f1_m: 0.0000e+00 - loss: 0.1261 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 21/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2210 - f1_m: 0.0000e+00 - loss: 0.1243 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 22/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2159 - f1_m: 0.0000e+00 - loss: 0.1237 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 23/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - accuracy: 0.2217 - f1_m: 0.0000e+00 - loss: 0.1218 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 24/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2146 - f1_m: 0.0000e+00 - loss: 0.1219 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 25/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2219 - f1_m: 0.0000e+00 - loss: 0.1199 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 26/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2223 - f1_m: 0.0000e+00 - loss: 0.1195 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 27/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2157 - f1_m: 0.0000e+00 - loss: 0.1193 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 28/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2203 - f1_m: 0.0000e+00 - loss: 0.1191 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 29/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2178 - f1_m: 0.0000e+00 - loss: 0.1184 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 30/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2162 - f1_m: 0.0000e+00 - loss: 0.1178 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 31/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2193 - f1_m: 0.0000e+00 - loss: 0.1176 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 32/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2224 - f1_m: 0.0000e+00 - loss: 0.1170 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 33/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2134 - f1_m: 0.0000e+00 - loss: 0.1169 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 34/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - accuracy: 0.2242 - f1_m: 0.0000e+00 - loss: 0.1161 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 35/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2137 - f1_m: 0.0000e+00 - loss: 0.1164 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 36/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2257 - f1_m: 0.0000e+00 - loss: 0.1159 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 37/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2210 - f1_m: 0.0000e+00 - loss: 0.1150 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 38/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2221 - f1_m: 0.0000e+00 - loss: 0.1152 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 39/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2188 - f1_m: 0.0000e+00 - loss: 0.1160 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 40/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2179 - f1_m: 0.0000e+00 - loss: 0.1145 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 41/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - accuracy: 0.2188 - f1_m: 0.0000e+00 - loss: 0.1148 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 42/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - accuracy: 0.2132 - f1_m: 0.0000e+00 - loss: 0.1153 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 43/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2181 - f1_m: 0.0000e+00 - loss: 0.1151 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 44/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - accuracy: 0.2169 - f1_m: 0.0000e+00 - loss: 0.1149 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 45/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2174 - f1_m: 0.0000e+00 - loss: 0.1147 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 46/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2165 - f1_m: 0.0000e+00 - loss: 0.1145 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 47/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2158 - f1_m: 0.0000e+00 - loss: 0.1140 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 48/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2193 - f1_m: 0.0000e+00 - loss: 0.1147 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 49/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - accuracy: 0.2207 - f1_m: 0.0000e+00 - loss: 0.1144 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 50/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2180 - f1_m: 0.0000e+00 - loss: 0.1135 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 51/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2192 - f1_m: 0.0000e+00 - loss: 0.1144 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 52/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2206 - f1_m: 0.0000e+00 - loss: 0.1140 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 53/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2200 - f1_m: 0.0000e+00 - loss: 0.1142 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 54/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2223 - f1_m: 0.0000e+00 - loss: 0.1141 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 55/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2170 - f1_m: 0.0000e+00 - loss: 0.1139 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 56/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2287 - f1_m: 0.0000e+00 - loss: 0.1137 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 57/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2146 - f1_m: 0.0000e+00 - loss: 0.1139 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 58/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - accuracy: 0.2191 - f1_m: 0.0000e+00 - loss: 0.1139 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 59/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2224 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 60/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2136 - f1_m: 0.0000e+00 - loss: 0.1134 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 61/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2197 - f1_m: 0.0000e+00 - loss: 0.1135 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 62/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2199 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 63/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2190 - f1_m: 0.0000e+00 - loss: 0.1141 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 64/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2174 - f1_m: 0.0000e+00 - loss: 0.1137 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 65/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2234 - f1_m: 0.0000e+00 - loss: 0.1136 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 66/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2162 - f1_m: 0.0000e+00 - loss: 0.1136 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 67/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2168 - f1_m: 0.0000e+00 - loss: 0.1140 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 68/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 199ms/step - accuracy: 0.2277 - f1_m: 0.0000e+00 - loss: 0.1131 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 69/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2169 - f1_m: 0.0000e+00 - loss: 0.1138 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 70/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2186 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 71/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2216 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 72/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2215 - f1_m: 0.0000e+00 - loss: 0.1130 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 73/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2261 - f1_m: 0.0000e+00 - loss: 0.1131 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 74/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2256 - f1_m: 0.0000e+00 - loss: 0.1130 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 75/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2237 - f1_m: 0.0000e+00 - loss: 0.1130 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 76/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2195 - f1_m: 0.0000e+00 - loss: 0.1136 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 77/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2220 - f1_m: 0.0000e+00 - loss: 0.1130 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 78/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2169 - f1_m: 0.0000e+00 - loss: 0.1137 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 79/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - accuracy: 0.2235 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 80/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2120 - f1_m: 0.0000e+00 - loss: 0.1136 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 81/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2196 - f1_m: 0.0000e+00 - loss: 0.1137 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 82/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2260 - f1_m: 0.0000e+00 - loss: 0.1134 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 83/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - accuracy: 0.2201 - f1_m: 0.0000e+00 - loss: 0.1135 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 84/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2220 - f1_m: 0.0000e+00 - loss: 0.1135 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 85/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2241 - f1_m: 0.0000e+00 - loss: 0.1135 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 86/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2213 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 87/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2190 - f1_m: 0.0000e+00 - loss: 0.1131 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 88/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - accuracy: 0.2129 - f1_m: 0.0000e+00 - loss: 0.1142 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 89/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - accuracy: 0.2255 - f1_m: 0.0000e+00 - loss: 0.1134 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 90/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2273 - f1_m: 0.0000e+00 - loss: 0.1134 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 91/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2229 - f1_m: 0.0000e+00 - loss: 0.1126 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 92/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2189 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 93/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2174 - f1_m: 0.0000e+00 - loss: 0.1141 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 94/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2154 - f1_m: 0.0000e+00 - loss: 0.1137 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 95/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2246 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 96/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2216 - f1_m: 0.0000e+00 - loss: 0.1137 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 97/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2221 - f1_m: 0.0000e+00 - loss: 0.1135 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 98/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2165 - f1_m: 0.0000e+00 - loss: 0.1137 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 99/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - accuracy: 0.2134 - f1_m: 0.0000e+00 - loss: 0.1140 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 100/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2166 - f1_m: 0.0000e+00 - loss: 0.1139 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 101/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2185 - f1_m: 0.0000e+00 - loss: 0.1136 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 102/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2167 - f1_m: 0.0000e+00 - loss: 0.1134 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 103/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2161 - f1_m: 0.0000e+00 - loss: 0.1142 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 104/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - accuracy: 0.2204 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 105/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2178 - f1_m: 0.0000e+00 - loss: 0.1134 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 106/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2227 - f1_m: 0.0000e+00 - loss: 0.1135 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 107/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - accuracy: 0.2242 - f1_m: 0.0000e+00 - loss: 0.1127 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 108/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2226 - f1_m: 0.0000e+00 - loss: 0.1136 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 109/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - accuracy: 0.2185 - f1_m: 0.0000e+00 - loss: 0.1136 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 110/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - accuracy: 0.2216 - f1_m: 0.0000e+00 - loss: 0.1137 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 111/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2211 - f1_m: 0.0000e+00 - loss: 0.1136 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 112/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - accuracy: 0.2222 - f1_m: 0.0000e+00 - loss: 0.1132 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 113/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - accuracy: 0.2255 - f1_m: 0.0000e+00 - loss: 0.1131 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 114/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2217 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 115/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2182 - f1_m: 0.0000e+00 - loss: 0.1136 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 116/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2227 - f1_m: 0.0000e+00 - loss: 0.1145 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 117/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2258 - f1_m: 0.0000e+00 - loss: 0.1134 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 118/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2191 - f1_m: 0.0000e+00 - loss: 0.1134 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 119/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2191 - f1_m: 0.0000e+00 - loss: 0.1141 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 120/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2137 - f1_m: 0.0000e+00 - loss: 0.1137 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 121/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2209 - f1_m: 0.0000e+00 - loss: 0.1137 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 122/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2241 - f1_m: 0.0000e+00 - loss: 0.1134 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 123/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2142 - f1_m: 0.0000e+00 - loss: 0.1138 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 124/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2221 - f1_m: 0.0000e+00 - loss: 0.1131 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 125/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2234 - f1_m: 0.0000e+00 - loss: 0.1126 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 126/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2220 - f1_m: 0.0000e+00 - loss: 0.1139 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 127/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2252 - f1_m: 0.0000e+00 - loss: 0.1129 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 128/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2205 - f1_m: 0.0000e+00 - loss: 0.1134 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 129/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2185 - f1_m: 0.0000e+00 - loss: 0.1129 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 130/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2291 - f1_m: 0.0000e+00 - loss: 0.1131 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 131/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - accuracy: 0.2193 - f1_m: 0.0000e+00 - loss: 0.1130 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 132/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2137 - f1_m: 0.0000e+00 - loss: 0.1139 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 133/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2168 - f1_m: 0.0000e+00 - loss: 0.1139 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 134/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - accuracy: 0.2186 - f1_m: 0.0000e+00 - loss: 0.1134 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 135/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2210 - f1_m: 0.0000e+00 - loss: 0.1130 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 136/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2182 - f1_m: 0.0000e+00 - loss: 0.1140 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 137/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2214 - f1_m: 0.0000e+00 - loss: 0.1132 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 138/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2156 - f1_m: 0.0000e+00 - loss: 0.1139 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 139/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2178 - f1_m: 0.0000e+00 - loss: 0.1141 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 140/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2166 - f1_m: 0.0000e+00 - loss: 0.1139 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 141/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2262 - f1_m: 0.0000e+00 - loss: 0.1136 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 142/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2247 - f1_m: 0.0000e+00 - loss: 0.1134 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 143/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - accuracy: 0.2218 - f1_m: 0.0000e+00 - loss: 0.1139 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 144/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2252 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 145/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2202 - f1_m: 0.0000e+00 - loss: 0.1136 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 146/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2250 - f1_m: 0.0000e+00 - loss: 0.1131 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 147/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2140 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 148/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 199ms/step - accuracy: 0.2229 - f1_m: 0.0000e+00 - loss: 0.1135 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 149/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - accuracy: 0.2212 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 150/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - accuracy: 0.2180 - f1_m: 0.0000e+00 - loss: 0.1138 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 151/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2184 - f1_m: 0.0000e+00 - loss: 0.1137 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 152/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2156 - f1_m: 0.0000e+00 - loss: 0.1131 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 153/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2241 - f1_m: 0.0000e+00 - loss: 0.1129 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 154/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2145 - f1_m: 0.0000e+00 - loss: 0.1138 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 155/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2154 - f1_m: 0.0000e+00 - loss: 0.1134 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 156/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2263 - f1_m: 0.0000e+00 - loss: 0.1132 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 157/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - accuracy: 0.2195 - f1_m: 0.0000e+00 - loss: 0.1135 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 158/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2213 - f1_m: 0.0000e+00 - loss: 0.1135 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 159/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2201 - f1_m: 0.0000e+00 - loss: 0.1132 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 160/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 168ms/step - accuracy: 0.2177 - f1_m: 0.0000e+00 - loss: 0.1136 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 161/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2218 - f1_m: 0.0000e+00 - loss: 0.1136 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 162/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2188 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 163/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2205 - f1_m: 0.0000e+00 - loss: 0.1135 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 164/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2158 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 165/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2251 - f1_m: 0.0000e+00 - loss: 0.1135 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 166/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2235 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 167/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2167 - f1_m: 0.0000e+00 - loss: 0.1136 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 168/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2265 - f1_m: 0.0000e+00 - loss: 0.1131 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 169/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2222 - f1_m: 0.0000e+00 - loss: 0.1128 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 170/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2216 - f1_m: 0.0000e+00 - loss: 0.1134 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 171/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2239 - f1_m: 0.0000e+00 - loss: 0.1130 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 172/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - accuracy: 0.2226 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 173/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2204 - f1_m: 0.0000e+00 - loss: 0.1131 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 174/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2208 - f1_m: 0.0000e+00 - loss: 0.1131 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 175/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - accuracy: 0.2239 - f1_m: 0.0000e+00 - loss: 0.1135 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 176/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - accuracy: 0.2257 - f1_m: 0.0000e+00 - loss: 0.1134 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 177/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2191 - f1_m: 0.0000e+00 - loss: 0.1130 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 178/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2185 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 179/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2218 - f1_m: 0.0000e+00 - loss: 0.1138 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 180/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2194 - f1_m: 0.0000e+00 - loss: 0.1140 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 181/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2198 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 182/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - accuracy: 0.2195 - f1_m: 0.0000e+00 - loss: 0.1138 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 183/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2199 - f1_m: 0.0000e+00 - loss: 0.1130 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 184/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2200 - f1_m: 0.0000e+00 - loss: 0.1137 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 185/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.2169 - f1_m: 0.0000e+00 - loss: 0.1133 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 186/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2204 - f1_m: 0.0000e+00 - loss: 0.1134 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 187/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2198 - f1_m: 0.0000e+00 - loss: 0.1136 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 188/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - accuracy: 0.2214 - f1_m: 0.0000e+00 - loss: 0.1136 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 189/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2241 - f1_m: 0.0000e+00 - loss: 0.1134 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 190/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2186 - f1_m: 0.0000e+00 - loss: 0.1129 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 191/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - accuracy: 0.2212 - f1_m: 0.0000e+00 - loss: 0.1129 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 192/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2220 - f1_m: 0.0000e+00 - loss: 0.1130 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 193/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2273 - f1_m: 0.0000e+00 - loss: 0.1136 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 194/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2211 - f1_m: 0.0000e+00 - loss: 0.1137 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 195/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2304 - f1_m: 0.0000e+00 - loss: 0.1126 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 196/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2151 - f1_m: 0.0000e+00 - loss: 0.1136 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 197/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2222 - f1_m: 0.0000e+00 - loss: 0.1131 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 198/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2262 - f1_m: 0.0000e+00 - loss: 0.1130 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 199/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.2157 - f1_m: 0.0000e+00 - loss: 0.1137 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 200/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.2177 - f1_m: 0.0000e+00 - loss: 0.1140 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbe3e2dedb0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.fit(dl, epochs=200, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699120/1879154529.py:21: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  series_tensor = torch.tensor(series, dtype=torch.float32)\n",
      "/tmp/ipykernel_1699120/1879154529.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_tensor = torch.tensor(label, dtype=torch.float32 )\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 80, 13])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    }
   ],
   "source": [
    "id= 55\n",
    "x = x_test[id].reshape((1,80,13))\n",
    "y_pred = rnn_model.predict(x)\n",
    "predicted_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0777,  0.0451, -0.0458,  ..., -0.1756, -0.1833, -0.1283],\n",
       "         [-0.3978, -0.5087, -0.4990,  ..., -0.7881, -0.8043, -0.1414],\n",
       "         [-1.0256, -0.9881, -0.9307,  ..., -0.5043, -0.6514, -0.5582],\n",
       "         ...,\n",
       "         [-0.5978, -0.7179, -0.6984,  ..., -0.6607, -0.6768, -0.6354],\n",
       "         [-0.9912, -0.9875, -0.9717,  ..., -0.8657, -0.9406, -0.8819],\n",
       "         [-0.1205, -0.1504, -0.2360,  ..., -0.2075, -0.1470, -0.2509]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n",
      "tensor(21)\n"
     ]
    }
   ],
   "source": [
    "print(predicted_classes)\n",
    "print(np.argmax(y_test[id], axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
